Result for Pegasos Algorithm

a) 

Result for Pegasos Multi-Class Algorithm

a) I was able to get the data from the files mnist_train.txt, mnist_test.txt, and transform them into feature vectors.

Calling: ['main.py', '-run'] arguments.
		-> Getting Test, Validation & Training Data from MNIST
		-> Starting to get Training & Validation Data
		-> Got Training & Validation Data
		-> Starting to get Test Data
			-> Got Test Data
			-> There are 2000 vectors for the Validation Set
			-> There are 1000 vectors for the Test Set
			-> Get Data Took 5.08846402168 seconds

The function that did that operation was: getData(). It traversed through and set each datapoint in the way: [number, [vector array]], so it was easy to parse and read through.

Then foreach point I did vector arithmetic to convert it from whichever number to -1, 0, 1: (((int(num) * 2) / (255)) - 1). This reduced the difficulties when compared to having a bunch of random numbers of random values (and also reduced time as I tried!). 

For some reason when it had random numbers it took longer (not performing the vector arithmetic) - I guess it would have been the dot product which would be higher, and therefore it would take longer to compute.

This part was pretty simple - I didn't get around to optimizing this section too much, but I made the attempt to reduce the operations to save on time. In comparison to part (1) the time taken for the vectors to load and parse for both the datasets was tiny.

b) This is the output of getting ten different weights by calling multipegasos() each time using a different classifier. The classifiers go from 0-9, and alter the answer. This then creates an array of all the weight vectors called allWeights, and then runs the test. 

The body of the function multipegasos() is very similar to the pegasos_svm_train() algorithm in part (1), but has to go and parse the data and find the greatest label before calling it.

-> Starting Training & Validation Process
		-> Starting to parse data for Pegasos Algorithm
		-> Dataset: Training Data
		-> Classification Number: 0
		-> Calling Pegasos SVM to start training
			-> Multi Took 1.53045797348 seconds
		-> Starting to Train Pegasos Algorithm
			-> Lower Than One: 196 Over One: 1804
			-> Number: 1 Value: 2964.01454118
			-> Lower Than One: 280 Over One: 1720
			-> Number: 2 Value: 2016.79787599
			-> Lower Than One: 324 Over One: 1676
			-> Number: 3 Value: 2007.60696933
			-> Lonwer Than One: 349 Over One: 1651
			-> Number: 4 Value: 2004.70538843
			-> Lower Than One: 371 Over One: 1629
			-> Number: 5 Value: 2003.28390888
			-> Took 12.2745079994 seconds
		
		This carries on for all Nine Classifications		

The multipegasostest() function takes input of the test data, all the weights by the 10 iterations using different classifications, and the classifications.

It goes through the data and finds the maximum score label, and returns it as the answer.

		-> Starting to parse data for Pegasos Tester Algorithm
		-> Dataset: Test Data
			-> Error: 168, out of: 1000. Has 16.8% errors
			-> Took 1.93281793594 seconds
-> Whole Algorithm: Took 153.278211117 seconds

The test error seems to be about ~16%, which I felt was a bit high, but when I tried to optimize it it didn't shift up or down too much.  

I followed all the different equations, and verified that most of my Vector additions, multiplications were working correctly. Therefore I feel that this is a pretty accurate result from the operations I've done.

c) My algorithm set the division to be 5, so k = 5. I was able to get a pretty good error, and average validation error with this. 

This model was kind of complex to think about - it was just splitting data and training then testing. It also took the longest time in comparison to all of them to divide the data and run through all the divisions with 10 different weights. But I think it's extremely efficient in predicting as it gives the smallest validation error, and also the smallest error in general. 

-> Starting Cross Validation Process
		-> Chosen to divided data into 5 blocks.
		-> Split into 5 blocks of 400 each!
			-> At process: 1
		-> Starting to parse data for Pegasos Algorithm
		-> Dataset: Training Data: Process ID: 1
		-> Classification Number: 0
		-> Calling Pegasos SVM to start training
			-> Multi Took 1.10887503624 seconds
		-> Starting to Train Pegasos Algorithm
			-> Lower Than One: 170 Over One: 1430
			-> Number: 1 Value: 2759.89707826
			-> Lower Than One: 226 Over One: 1374
			-> Number: 2 Value: 1617.44858662
			-> Lower Than One: 265 Over One: 1335
			-> Number: 3 Value: 1607.81485228
			-> Lower Than One: 285 Over One: 1315
			-> Number: 4 Value: 1605.09761466
			-> Lower Than One: 307 Over One: 1293
			-> Number: 5 Value: 1603.52659309
			-> Took 9.95808291435 seconds

			It ran this for each of the 9 Classifications, for when k = 5, so when the data was divided 5 times. It does each classification for 5 iterations. 

			So the process is 5 iterations for each classification, 9 classifications, and 5 divisions of data. (5 * 9 * 5 traversals through the data)

Then it runs the average errors in classification & in validation

		-> Average errors in classification 106.4, 10.64%
		-> Average errors in validating data 5.32%
		-> Whole Algorithm: Took 579.643028975 seconds

This is a decent average of errors - it's a smaller error than the one I presumed it would be for this class. It's about 106.4/1000 misclassifications, which is about 10.64%.

That seems like it's on par with the error that I expected. Now I have reported an average validation error, and an average error in classification.

The next step is to alter lambda to give the smallest cross-validation error. (The running time might be a bit higher as I was running all these lambda values asynchronously)

Lambda = 2^-5, classification error: 13.44%
Lambda = 2^-4, classification error: 13.02
Lambda = 2^-3, classification error: 10.64
Lambda = 2^-2, classification error: 10.12
Lambda = 2^-1, classification error: 9.82
Lambda = 2^0, classification error: 10.1
Lambda = 2^1, classification error: 11.13

Also noting, all of these are averages:

Lambda = 2^-5, validating data error: 6.72%
Lambda = 2^-4, validating data error: 6.51%
Lambda = 2^-3, validating data error: 5.32
Lambda = 2^-2, validating data error: 5.06
Lambda = 2^-1, validating data error: 4.91
Lambda = 2^0, validating data error: 5.05
Lambda = 2^1, validating data error: 5.67

Drawn on paper (Check behind this page)

Cross Validation Error vs set of [-5, -4, -3, -2, -1, 0, 1]

Seems like the best value for both cases (classification error & validation error) is it being 2^-1, or -1 as lambda. That gives the lowest Validation error of 4.91, and lowest classification error of 9.82%.

d) 